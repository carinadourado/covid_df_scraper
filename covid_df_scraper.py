# -*- coding: utf-8 -*-
"""projeto_final_pensamento_computacional.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iDZZ_pYNHLgHgMl2uVfePKrVjhY7Sfd8
"""

import requests
from bs4 import BeautifulSoup

url = "https://www.saude.df.gov.br/boletinsinformativos-divep-cieves/"
resposta = requests.get(url)
html = resposta.text

def extrai_dados_bs(html):
  links = []
  soup = BeautifulSoup(html, "html.parser")
  tags_a = soup.find_all("a")
  for tag in tags_a:
    if tag.text.startswith("Informe nº "): #extrai o nº do boletim
      informe = tag.text.replace("Informe nº ", "")
      link = tag.attrs["href"] #extra os links dos boletins
      links.append({"informe":informe , "link": link})
  return links

import csv

import requests

url = "https://www.saude.df.gov.br/boletinsinformativos-divep-cieves/"
resposta = requests.get(url)
arquivo = open("informes_covid_df.csv", mode="w") #cria arquivo csv 
escritor = csv.DictWriter(arquivo, fieldnames=["informe", "link"]) #define colunas
escritor.writeheader()
for link_dict in extrai_dados_bs(html):
  escritor.writerow(link_dict)
arquivo.close()

""" # Criando a classe LinksCovid"""

import csv

import requests
from bs4 import BeautifulSoup


class LinksCovid:
  def baixar_html(self):
    url = "https://www.saude.df.gov.br/boletinsinformativos-divep-cieves/"
    resposta = requests.get(url)
    self.html = resposta.text  

  def extrai_dados_bs(self):
    self.links = []
    soup = BeautifulSoup(html, "html.parser")
    tags_a = soup.find_all("a")
    for tag in tags_a:
      if tag.text.startswith("Informe nº "):
        informe = tag.text
        link = tag.attrs["href"]
        self.links.append({"informe":informe , "link": link})

  def escreve_csv(self, nome_arquivo):
    url = "https://www.saude.df.gov.br/boletinsinformativos-divep-cieves/"
    resposta = requests.get(url)
    arquivo = open(nome_arquivo, mode="w")
    escritor = csv.DictWriter(arquivo, fieldnames=["informe", "link"])
    escritor.writeheader()
    for link_dict in self.links:
      escritor.writerow(link_dict)
    arquivo.close()

  def executa_funcoes(self, nome_arquivo):
    self.baixar_html()
    self.extrai_dados_bs()
    self.escreve_csv(nome_arquivo)

extrator = LinksCovid() # extrator com métodos
extrator.baixar_html()
extrator.extrai_dados_bs()
extrator.escreve_csv("links_classe.csv")

extrator2 = LinksCovid() # extrator executa
extrator2 = extrator.executa_funcoes("links_classe2.csv")